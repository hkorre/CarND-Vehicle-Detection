{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection and Tracking\n",
    "\n",
    "---\n",
    "By Hasan Korre\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "* Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "* Apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector. Retrain your classifier and hopefully see improved accuracy.\n",
    "  * Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "* Using a Decision Tree classifier, explore the feature importances and consider pruning or adding new features.\n",
    "* Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "* Run your pipeline on a video stream and implement tracking to follow detected vehicles.\n",
    "* Create a heat map of recurring detections frame by frame to reject outliers.\n",
    "* Estimate a bounding box for vehicles detected.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "from random import randint\n",
    "from sklearn import tree\n",
    "from skimage.feature import blob_doh, corner_peaks, hog\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.morphology import watershed\n",
    "from scipy import ndimage as ndi\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('Success: Imported libraries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicles Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in example images\n",
    "img_vehicle_far = imread('vehicles/GTI_Far/image0000.png')\n",
    "img_vehicle_left = imread('vehicles/GTI_Left/image0009.png')\n",
    "img_vehicle_middle = imread('vehicles/GTI_MiddleClose/image0000.png')\n",
    "img_vehicle_right = imread('vehicles/GTI_Right/image0000.png')\n",
    "img_vehicle_kitti = imread('vehicles/KITTI_extracted/1.png')\n",
    "\n",
    "print('img shape = ', img_vehicle_far.shape)\n",
    "train_height = img_vehicle_far.shape[0]\n",
    "train_width = img_vehicle_far.shape[1]\n",
    "train_channels = img_vehicle_far.shape[2]\n",
    "\n",
    "# Display\n",
    "f1, (a11, a12, a13, a14, a15) = plt.subplots(1, 5, figsize=(8, 6))\n",
    "f1.tight_layout()\n",
    "a11.imshow(img_vehicle_far)\n",
    "a11.set_title('Vehicle - Far', fontsize=10)\n",
    "a12.imshow(img_vehicle_left)\n",
    "a12.set_title('Vehicle - Left', fontsize=10)\n",
    "a13.imshow(img_vehicle_middle)\n",
    "a13.set_title('Vehicle - Middle', fontsize=10)\n",
    "a14.imshow(img_vehicle_right)\n",
    "a14.set_title('Vehicle - Right', fontsize=10)\n",
    "a15.imshow(img_vehicle_kitti)\n",
    "a15.set_title('Vehicle - Kitti', fontsize=10)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Vehicle Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in example images\n",
    "img_nonVehicle_gti1 = imread('non-vehicles/GTI/image1.png')\n",
    "img_nonVehicle_gti3000 = imread('non-vehicles/GTI/image3000.png')\n",
    "img_nonVehicle_gti700 = imread('non-vehicles/GTI/image700.png')\n",
    "img_nonVehicle_extra1 = imread('non-vehicles/Extras/extra1.png')\n",
    "img_nonVehicle_extra5000 = imread('non-vehicles/Extras/extra5000.png')\n",
    "\n",
    "# Display\n",
    "f1, (a11, a12, a13, a14, a15) = plt.subplots(1, 5, figsize=(8, 6))\n",
    "f1.tight_layout()\n",
    "a11.imshow(img_nonVehicle_gti1)\n",
    "a11.set_title('NonVehicle - GTI 1', fontsize=10)\n",
    "a12.imshow(img_nonVehicle_gti3000)\n",
    "a12.set_title('NonVehicle - GTI 3000', fontsize=10)\n",
    "a13.imshow(img_nonVehicle_gti700)\n",
    "a13.set_title('NonVehicle - GTI 700', fontsize=10)\n",
    "a14.imshow(img_nonVehicle_extra1)\n",
    "a14.set_title('NonVehicle - Extra 1', fontsize=10)\n",
    "a15.imshow(img_nonVehicle_extra5000)\n",
    "a15.set_title('NonVehicle - Extra 5000', fontsize=10)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lists of image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_filenames_to_list(list_, filenames_):\n",
    "    for filename in filenames_:\n",
    "        list_.append(filename)\n",
    "\n",
    "# Vehicles\n",
    "car_filepaths = []\n",
    "car_directories = ['vehicles/GTI_Far/',\n",
    "                   'vehicles/GTI_Left/',\n",
    "                   'vehicles/GTI_MiddleClose/',\n",
    "                   'vehicles/GTI_Right/',\n",
    "                   'vehicles/KITTI_extracted/']\n",
    "for folder in car_directories:\n",
    "    glob_filenames = glob.glob(folder + '*.png')\n",
    "    add_filenames_to_list(car_filepaths, glob_filenames)\n",
    "\n",
    "\n",
    "# Non-Vehicles\n",
    "notcar_filepaths = []\n",
    "notcar_directories = ['non-vehicles/GTI/',\n",
    "                      'non-vehicles/Extras/']\n",
    "for folder in notcar_directories:\n",
    "    glob_filenames = glob.glob(folder + '*.png')\n",
    "    add_filenames_to_list(notcar_filepaths, glob_filenames)\n",
    "\n",
    "\n",
    "print('# car_filepaths = {}'.format(len(car_filepaths)))\n",
    "print('# notcar_filepaths = {}'.format(len(notcar_filepaths)))\n",
    "print('Success: Created image name lists.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to return HOG features vector and visualization\n",
    "def get_hog_features(img_, orient_, pix_per_cell_, cell_per_block_, vis_=False):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis_ == True:\n",
    "        features, hog_image = hog(img_, orientations=orient_, pixels_per_cell=(pix_per_cell_, pix_per_cell_),\n",
    "                                  cells_per_block=(cell_per_block_, cell_per_block_), transform_sqrt=True, \n",
    "                                  visualise=vis_, feature_vector=True)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img_, orientations=orient_, pixels_per_cell=(pix_per_cell_, pix_per_cell_),\n",
    "                       cells_per_block=(cell_per_block_, cell_per_block_), transform_sqrt=True, \n",
    "                       visualise=vis_, feature_vector=True)\n",
    "        return features\n",
    "\n",
    "\n",
    "'''\n",
    "test it...\n",
    "'''\n",
    "PIX_PER_CELL = 8\n",
    "CELL_PER_BLOCK = 2\n",
    "ORIENT = 9\n",
    "\n",
    "hog_test_img = imread('vehicles/GTI_Left/image0009.png')\n",
    "hog_test_gray = cv2.cvtColor(hog_test_img, cv2.COLOR_RGB2GRAY)\n",
    "features, hog_test_result = get_hog_features(hog_test_gray, ORIENT, PIX_PER_CELL, CELL_PER_BLOCK, vis_=True)\n",
    "\n",
    "# Display\n",
    "f1, (a11, a12) = plt.subplots(1, 2, figsize=(4, 3))\n",
    "f1.tight_layout()\n",
    "a11.imshow(hog_test_img)\n",
    "a11.set_title('Test Image', fontsize=10)\n",
    "a12.imshow(hog_test_result, cmap='gray')\n",
    "a12.set_title('HOG Image', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to extract features from a list of images\n",
    "#   uses Lab color space and only hog features\n",
    "def extract_features(img_, spatial_size_=(32, 32),\n",
    "                           hist_bins_=32, hist_range_=(0, 256), orient_=9, \n",
    "                           pix_per_cell_=8, cell_per_block_=2):\n",
    "    # apply color conversion\n",
    "    img_lab = cv2.cvtColor(img_, cv2.COLOR_RGB2Lab) \n",
    "    # create feature vectors\n",
    "    hog_features_0 = get_hog_features(img_lab[:,:,0], orient_, \n",
    "            pix_per_cell_, cell_per_block_, vis_=False)\n",
    "    hog_features_1 = get_hog_features(img_lab[:,:,1], orient_, \n",
    "            pix_per_cell_, cell_per_block_, vis_=False)\n",
    "    hog_features_2 = get_hog_features(img_lab[:,:,2], orient_, \n",
    "            pix_per_cell_, cell_per_block_, vis_=False)\n",
    "    # concat features\n",
    "    return np.concatenate((hog_features_0, hog_features_1, hog_features_2))\n",
    "\n",
    "\n",
    "# Define a function to extract features from a list of images\n",
    "def extract_features_files(filepaths_, spatial_size_=(32, 32),\n",
    "                           hist_bins_=32, hist_range_=(0, 256), orient_=9, \n",
    "                           pix_per_cell_=8, cell_per_block_=2):\n",
    "    features_list = []   #list to append feature vectors to\n",
    "    for filepath in filepaths_:\n",
    "        image = imread(filepath)\n",
    "        #image = image.astype(np.float32)\n",
    "        features_single = extract_features(image, spatial_size_,\n",
    "                           hist_bins_, hist_range_, orient_, \n",
    "                           pix_per_cell_, cell_per_block_)\n",
    "        \n",
    "        if np.isnan(features_single).any():\n",
    "            print(filepath)\n",
    "        \n",
    "        features_list.append(features_single)\n",
    "    return features_list\n",
    "\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "# find features\n",
    "print('Extracting car features...')\n",
    "car_features = extract_features_files(car_filepaths, orient_=ORIENT, \n",
    "                                      pix_per_cell_=PIX_PER_CELL, \n",
    "                                      cell_per_block_=CELL_PER_BLOCK)\n",
    "print('Extracting non-car features...')\n",
    "notcar_features = extract_features_files(notcar_filepaths, orient_=ORIENT, \n",
    "                                         pix_per_cell_=PIX_PER_CELL, \n",
    "                                         cell_per_block_=CELL_PER_BLOCK)\n",
    "print('Features found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_features(car_features_, notcar_features_):    \n",
    "    # Create an array stack of feature vectors\n",
    "    X = np.vstack((car_features_, notcar_features_)).astype(np.float64)\n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Get mean=0 and variance=1\n",
    "    return X_scaler.transform(X), X_scaler\n",
    "\n",
    "# Define the labels vector\n",
    "def create_labels(car_features_, notcar_features_):\n",
    "    return np.hstack((np.ones(len(car_features_)), np.zeros(len(notcar_features_))))\n",
    "\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "scaled_features, data_scaler = preprocess_features(car_features, notcar_features)\n",
    "total_labels = create_labels(car_features, notcar_features)\n",
    "\n",
    "print('scaled_features.shape = ', scaled_features.shape)\n",
    "print('total_labels.shape = ', total_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split up data into randomized training and test sets\n",
    "def split_test_and_train(X_, Y_, test_size_=0.2):\n",
    "    start_rand = np.random.randint(0, 100)\n",
    "    X_train, X_test, Y_train, Y_test = \\\n",
    "      train_test_split(X_, Y_, test_size=test_size_, random_state=start_rand)\n",
    "    return (X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "# Calibrated Linear Support-Vector-Classifier\n",
    "def train_svc(X_train_, X_test_, Y_train_, Y_test_, c_=1.0):\n",
    "    # setup linear support-vector-classifier\n",
    "    svc = LinearSVC(C=c_)\n",
    "    # setup and train calibrated classifier\n",
    "    cal_svc = CalibratedClassifierCV(svc)\n",
    "    cal_svc.fit(X_train_, Y_train_)\n",
    "    # Check the score of the classifier\n",
    "    print('Train Accuracy of SVC = ', cal_svc.score(X_train_, Y_train_))\n",
    "    print('Test Accuracy of SVC = ', cal_svc.score(X_test_, Y_test_))\n",
    "    return cal_svc\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "  split_test_and_train(scaled_features, total_labels)\n",
    "print('Split data.')\n",
    "trained_svc = train_svc(x_train, x_test, y_train, y_test, 1000.0)\n",
    "print('Trained SVC.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_boxes(img_, bboxes_, color_=(0, 0, 255), thick_=6):\n",
    "    img_copy = np.copy(img_)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes_:\n",
    "        cv2.rectangle(img_copy, bbox[0], bbox[1], color_, thick_)\n",
    "    return img_copy\n",
    "\n",
    "# Define a function that takes an image,\n",
    "#   start and stop positions in both x and y, \n",
    "#   window size (x and y dimensions),  \n",
    "#   and overlap fraction (for both x and y)\n",
    "def slide_window(img_, x_start_stop_=[None, None], y_start_stop_=[None, None], \n",
    "                    xy_window_=(64, 64), xy_overlap_=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop_[0] == None:\n",
    "        x_start_stop_[0] = 0\n",
    "    if x_start_stop_[1] == None:\n",
    "        x_start_stop_[1] = img_.shape[1]\n",
    "    if y_start_stop_[0] == None:\n",
    "        y_start_stop_[0] = 0\n",
    "    if y_start_stop_[1] == None:\n",
    "        y_start_stop_[1] = img_.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop_[1] - x_start_stop_[0]\n",
    "    yspan = y_start_stop_[1] - y_start_stop_[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window_[0]*(1 - xy_overlap_[0]))\n",
    "    ny_pix_per_step = np.int(xy_window_[1]*(1 - xy_overlap_[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_windows = np.int(xspan/nx_pix_per_step) - 1\n",
    "    ny_windows = np.int(yspan/ny_pix_per_step) - 1\n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop_[0]\n",
    "            endx = startx + xy_window_[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop_[0]\n",
    "            endy = starty + xy_window_[1]\n",
    "            # window limits\n",
    "            startx = 0 if startx < 0 else startx\n",
    "            endx = img_.shape[1] if endx > img_.shape[1] else endx\n",
    "            starty = 0 if starty < 0 else starty\n",
    "            endy = img_.shape[0] if endy > img_.shape[0] else endy\n",
    "            # Append window position to list\n",
    "            if (endx-startx == xy_window_[0]) and (endy-starty == xy_window_[1]):\n",
    "                window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "\n",
    "'''\n",
    "test it...\n",
    "'''\n",
    "TEST_IMG = imread('test_images/test1.jpg')\n",
    "WINDOW_SIZE = (64,64) #(128,128)\n",
    "OVERLAP = (0.75,0.75)\n",
    "Y_START_STOP = [int(TEST_IMG.shape[0]*0.55), int(TEST_IMG.shape[0]*0.8)]\n",
    "test_windows = slide_window(TEST_IMG, \n",
    "                            x_start_stop_=[None, None], y_start_stop_=Y_START_STOP, \n",
    "                            xy_window_=WINDOW_SIZE, xy_overlap_=OVERLAP)\n",
    "img_windows = draw_boxes(TEST_IMG, test_windows, color_=(0, 0, 255), thick_=6)\n",
    "plt.imshow(img_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_cars(img_, window_list_, window_size_, scaler_, classifier_):\n",
    "    img_window = np.zeros(window_size_)\n",
    "    num_detections = 0\n",
    "    window_list_detections = []\n",
    "    # for each window...\n",
    "    for bbox in window_list_:\n",
    "        # extract part of img_\n",
    "        top_L_x = bbox[0][0]\n",
    "        top_L_y = bbox[0][1]\n",
    "        bot_R_x = bbox[1][0]\n",
    "        bot_R_y = bbox[1][1]\n",
    "        img_window = img_[top_L_y:bot_R_y,top_L_x:bot_R_x,:]\n",
    "        # resize to 64x64\n",
    "        img_resized = cv2.resize(img_window, (train_height,train_width))\n",
    "        # extract features\n",
    "        features = extract_features(img_resized, orient_=ORIENT, \n",
    "                                    pix_per_cell_=PIX_PER_CELL, cell_per_block_=CELL_PER_BLOCK)\n",
    "        features = features.reshape(1, -1)   #stop the executor from complaining\n",
    "        # preprocess features\n",
    "        scaled_features = scaler_.transform(features)\n",
    "        # predict with svc\n",
    "        prediction = classifier_.predict(scaled_features)\n",
    "        prediction_prob_1 = classifier_.predict_proba(scaled_features)[0][1]\n",
    "        if prediction == 1 and prediction_prob_1 > 0.75:\n",
    "            window_list_detections.append(bbox)\n",
    "            num_detections += 1\n",
    "\n",
    "    #print('{} detections.'.format(num_detections))\n",
    "    return window_list_detections\n",
    "\n",
    "# map the inputs to the function blocks\n",
    "color_dict = {0: (255,   0,   0),  #red\n",
    "              1: (  0, 255,   0),  #green\n",
    "              2: (  0,   0, 255),  #blue\n",
    "              3: (255, 255,   0),  #yellow\n",
    "              4: (255,   0, 255),  #purple\n",
    "              5: (255, 140,   0)   #orange\n",
    "}\n",
    "\n",
    "def draw_detections(img_, detections_list_, draw_color_=None):\n",
    "    if draw_color_ is None:\n",
    "        draw_color_ = color_dict[randint(0,5)]\n",
    "    return draw_boxes(img_, detections_list_, color_=draw_color_)\n",
    "\n",
    "\n",
    "'''\n",
    "test it...\n",
    "'''\n",
    "detections_list = find_cars(TEST_IMG, test_windows, WINDOW_SIZE, data_scaler, trained_svc)\n",
    "img_boxed_cars = draw_detections(TEST_IMG, detections_list)\n",
    "plt.imshow(img_boxed_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find cars with different size windows\n",
    "def find_cars_multiSize(img_, window_sizes_, overlaps_, startStops_, scaler_, classifier_):\n",
    "    detections_list_total = []\n",
    "    #for size in window_sizes_:\n",
    "    for size, overlap, start_stop in zip(window_sizes_, overlaps_, startStops_):\n",
    "        windows = slide_window(img_, x_start_stop_=[None, None], y_start_stop_=start_stop, \n",
    "                               xy_window_=size, xy_overlap_=overlap)\n",
    "        detections_list = find_cars(img_, windows, size, scaler_, classifier_)\n",
    "        detections_list_total = detections_list_total + detections_list\n",
    "    return detections_list_total\n",
    "\n",
    "def findAndDraw_cars_multiSize(img_, window_sizes_, overlaps_, startStops_, scaler_, classifier_):\n",
    "    detections = find_cars_multiSize(img_, window_sizes_, overlaps_, startStops_, scaler_, classifier_)\n",
    "    return draw_detections(np.copy(img_), detections)    \n",
    "    \n",
    "'''\n",
    "test it...\n",
    "'''\n",
    "TEST_IMG = imread('test_images/test1.jpg')\n",
    "WINDOW_SIZES_MULTI = [(64,64),(128,128)]\n",
    "#OVERLAP_MULTI = [(0.65,0.65),(0.75,0.75)]\n",
    "OVERLAP_MULTI = [(0.8,0.8),(0.8,0.8)]\n",
    "START_STOP_MULTI = [[int(TEST_IMG.shape[0]*0.55), int(TEST_IMG.shape[0]*0.8)],\n",
    "                    [int(TEST_IMG.shape[0]*0.55),None]]\n",
    "img_detect_cars = findAndDraw_cars_multiSize(TEST_IMG, WINDOW_SIZES_MULTI, OVERLAP_MULTI, \n",
    "                                             START_STOP_MULTI, data_scaler, trained_svc)\n",
    "plt.imshow(img_detect_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def detect_on_test_images(img_names_, window_sizes_, overlaps_, startStops_, scaler_, classifier_):\n",
    "    is_left = True\n",
    "    for index, name in enumerate(img_names_):\n",
    "        print(name)\n",
    "        image = imread('test_images/' + name)\n",
    "    \n",
    "        image = findAndDraw_cars_multiSize(image, window_sizes_, overlaps_, startStops_, scaler_, classifier_)\n",
    "    \n",
    "        if is_left:\n",
    "            fig = plt.figure(figsize=(8, 6))\n",
    "            a=fig.add_subplot(1,2,1)\n",
    "            is_left = False\n",
    "        else:    \n",
    "            a=fig.add_subplot(1,2,2)\n",
    "            is_left = True\n",
    "        a.set_title(name)\n",
    "        plt.imshow(image)\n",
    "        \n",
    "'''\n",
    "test it...\n",
    "'''\n",
    "IMG_NAMES = os.listdir('test_images/')\n",
    "detect_on_test_images(IMG_NAMES, WINDOW_SIZES_MULTI, OVERLAP_MULTI, START_STOP_MULTI, data_scaler, trained_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEST_IMG = imread('test_images/test6.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Heat Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test udacity suggested code\n",
    "\n",
    "def add_heat(heatmap_, bbox_list_):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list_:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap_[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap_\n",
    "\n",
    "def apply_threshold(heatmap_, threshold_):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap_[heatmap_ < threshold_] = 0\n",
    "    heatmap_[heatmap_ > 0] = 1\n",
    "    return heatmap_\n",
    "\n",
    "def bbox_from_labels(labels_):\n",
    "    bbox_list = []\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels_[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels_[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        bbox_list.append(bbox)        \n",
    "    return bbox_list\n",
    "\n",
    "def bboxes_from_detections(img_, detections_, threshold_):\n",
    "    heatmap = np.zeros((img_.shape[0],img_.shape[1]))\n",
    "    heatmap = add_heat(heatmap, detections_)\n",
    "    heatmap = apply_threshold(heatmap, threshold_)\n",
    "    labels = label(heatmap)\n",
    "    return bbox_from_labels(labels) \n",
    "\n",
    "\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "'''\n",
    "Test it...\n",
    "'''\n",
    "detections_for_heatmap = find_cars_multiSize(TEST_IMG, WINDOW_SIZES_MULTI, OVERLAP_MULTI, \n",
    "                                             START_STOP_MULTI, data_scaler, trained_svc)\n",
    "combined_boxes = bboxes_from_detections(TEST_IMG, detections_for_heatmap, 1)\n",
    "img_combined_box = draw_detections(TEST_IMG, combined_boxes)\n",
    "plt.imshow(img_combined_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bound_test_images(img_names_, window_sizes_, overlap_, startStops_, scaler_, classifier_):\n",
    "    is_left = True\n",
    "    for index, name in enumerate(img_names_):\n",
    "        print(name)\n",
    "        image = imread('test_images/' + name)\n",
    "        \n",
    "        detections = find_cars_multiSize(image, window_sizes_, overlap_, startStops_, scaler_, classifier_)\n",
    "        if len(detections) != 0:\n",
    "            combined_boxes = bboxes_from_detections(TEST_IMG, detections, 1)\n",
    "            image = draw_detections(image, combined_boxes)\n",
    "\n",
    "        # display\n",
    "        if is_left:\n",
    "            fig = plt.figure(figsize=(8, 6))\n",
    "            a=fig.add_subplot(1,2,1)\n",
    "            is_left = False\n",
    "        else:    \n",
    "            a=fig.add_subplot(1,2,2)\n",
    "            is_left = True\n",
    "        a.set_title(name)\n",
    "        plt.imshow(image)\n",
    "        \n",
    "'''\n",
    "test it...\n",
    "'''\n",
    "IMG_NAMES = os.listdir('test_images/')\n",
    "bound_test_images(IMG_NAMES, WINDOW_SIZES_MULTI, OVERLAP_MULTI, START_STOP_MULTI, data_scaler, trained_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard-Negative Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run if not done already..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# $ mkdir non-vehicles/false_positives\n",
    "\n",
    "from matplotlib import interactive\n",
    "interactive(True)\n",
    "\n",
    "def check_false_positive(img_windowed_, name_):\n",
    "    false_positive_num = 0\n",
    "    plt.imshow(img_windowed_)\n",
    "    plt.show()\n",
    "    is_detection = bool(int(input(\"Is this a real detection (0,1): \")))\n",
    "    print (\"you entered...\", is_detection)\n",
    "    if not is_detection:\n",
    "        filename = 'non-vehicles/false_positives/' + name_ + '_' + str(false_positive_num) + '.png'\n",
    "        imsave(filename, img_windowed_)\n",
    "        print('saved as {}'.format(filename))\n",
    "        false_positive_num += 1     \n",
    "\n",
    "def find_cars_review(img_, window_list_, window_size_, scaler_, classifier_):\n",
    "    rand_color = color_dict[randint(0,5)]\n",
    "    imcopy = np.copy(img_)\n",
    "    img_window = np.zeros(window_size_)\n",
    "    num_detections = 0\n",
    "    window_list_detections = []\n",
    "    # for each window...\n",
    "    bbox_num = 0\n",
    "    for bbox in window_list_:\n",
    "        # extract part of img_\n",
    "        top_L_x = bbox[0][0]\n",
    "        top_L_y = bbox[0][1]\n",
    "        bot_R_x = bbox[1][0]\n",
    "        bot_R_y = bbox[1][1]\n",
    "        img_window = img_[top_L_y:bot_R_y,top_L_x:bot_R_x,:]\n",
    "        # resize to 64x64\n",
    "        img_resized = cv2.resize(img_window, (train_height, train_width))\n",
    "        # extract features\n",
    "        features = extract_features(img_resized, orient_=ORIENT, \n",
    "                                    pix_per_cell_=PIX_PER_CELL, cell_per_block_=CELL_PER_BLOCK)\n",
    "        features = features.reshape(1, -1)   #stop the executor from complaining\n",
    "        # preprocess features\n",
    "        scaled_features = scaler_.transform(features)\n",
    "        # predict with svc\n",
    "        if classifier_.predict(scaled_features) == 1:\n",
    "            window_list_detections.append(bbox)\n",
    "            num_detections += 1\n",
    "            check_false_positive(img_resized, 'bbox'+str(bbox_num))\n",
    "        bbox_num += 1\n",
    "\n",
    "    print('{} detections.'.format(num_detections))\n",
    "    return window_list_detections \n",
    "\n",
    "def find_cars_multiSize_review(img_, window_sizes_, scaler_, classifier_):\n",
    "    imcopy = np.copy(img_)\n",
    "    window_detections_list_total = []\n",
    "    for size in window_sizes_:\n",
    "        #print('detecting in window size {}...'.format(size))\n",
    "        windows = slide_window(imcopy, x_start_stop_=[None, None], y_start_stop_=Y_START_STOP, \n",
    "                    xy_window_=size, xy_overlap_=OVERLAP)\n",
    "        window_detections_list = find_cars_review(imcopy, windows, WINDOW_SIZE, \n",
    "                                                  scaler_, classifier_)\n",
    "        window_detections_list_total = window_detections_list_total + window_detections_list\n",
    "    imcopy = print_bboxes(img_, window_detections_list_total) \n",
    "    return imcopy\n",
    "\n",
    "\n",
    "'''\n",
    "Let's try it...\n",
    "'''\n",
    "is_left = True\n",
    "img_names = os.listdir('test_images/')\n",
    "\n",
    "for index, name in enumerate(img_names):\n",
    "    image = imread('test_images/' + name)\n",
    "    image = find_cars_multiSize_review(image, WINDOW_SIZES_MULTI, OVERLAP_MULTI, START_STOP_MULTI, data_scaler, trained_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get new list of non-vehicle images\n",
    "notcar_filepaths = []\n",
    "notcar_directories = ['non-vehicles/GTI/',\n",
    "                      'non-vehicles/Extras/',\n",
    "                      'non-vehicles/false_positives/']\n",
    "for folder in notcar_directories:\n",
    "    glob_filenames = glob.glob(folder + '*.png')\n",
    "    add_filenames_to_list(notcar_filepaths, glob_filenames)\n",
    "\n",
    "\n",
    "print('# car_filepaths = {}'.format(len(car_filepaths)))\n",
    "print('# notcar_filepaths = {}'.format(len(notcar_filepaths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# retrain...\n",
    "car_features = extract_features_files(car_filepaths, orient_=ORIENT,\n",
    "                                      pix_per_cell_=PIX_PER_CELL, \n",
    "                                      cell_per_block_=CELL_PER_BLOCK)\n",
    "notcar_features = extract_features_files(notcar_filepaths, orient_=ORIENT, \n",
    "                                         pix_per_cell_=PIX_PER_CELL, \n",
    "                                         cell_per_block_=CELL_PER_BLOCK)\n",
    "print('Features found.')\n",
    "\n",
    "# preproces data (redo on color space)\n",
    "scaled_features, data_scaler = preprocess_features(car_features, notcar_features)\n",
    "total_labels = create_labels(car_features, notcar_features)\n",
    "print('Data preprocessed.')\n",
    "\n",
    "# split and train (redo on color space)\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "  split_test_and_train(scaled_features, total_labels)\n",
    "trained_svc = train_svc(x_train, x_test, y_train, y_test, 1000.0)\n",
    "print('SVC trained.')\n",
    "\n",
    "# find the cars\n",
    "detect_on_test_images(IMG_NAMES, WINDOW_SIZES_MULTI, OVERLAP_MULTI, START_STOP_MULTI, data_scaler, trained_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bound_test_images(IMG_NAMES, WINDOW_SIZES_MULTI, OVERLAP_MULTI, START_STOP_MULTI, data_scaler, trained_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Grab Frame from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grab_video_frame(filepath_, frame_):\n",
    "    clip = VideoFileClip(filepath_)\n",
    "    return clip.get_frame(frame_)\n",
    "\n",
    "# image should be RGB\n",
    "def save_image(img_, filepath_):\n",
    "    mpimg.imsave(filepath_, img_)\n",
    "\n",
    "\n",
    "## try it ######\n",
    "frame_num = 30\n",
    "test_frame = grab_video_frame('project_video.mp4', frame_num)\n",
    "plt.imshow(test_frame)\n",
    "\n",
    "'''\n",
    "SAVE_FOLDER = 'test_images/'\n",
    "save_name = SAVE_FOLDER + 'project_{}.jpg'.format(frame_num)\n",
    "save_image(test_frame, save_name)\n",
    "'''\n",
    "\n",
    "print('Success: Defined functions to grab video frames.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# VideoProcessor Class\n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self):\n",
    "        self._frame_index = 0\n",
    "        self._FRAME_AGGREGATE = 10\n",
    "        self._detection_list_total = None\n",
    "        self._bbox_list_recent = None\n",
    "        self._threshold = 2\n",
    "    \n",
    "    def _aggregate_detections(self, detections_):\n",
    "        if self._detection_list_total is None:\n",
    "            self._detection_list_total = detections_\n",
    "        else:\n",
    "            self._detection_list_total.extend(detections_)\n",
    "\n",
    "    #External API\n",
    "    def process_image(self, image_):\n",
    "        # find detections\n",
    "        detections = find_cars_multiSize(image_, WINDOW_SIZES_MULTI, OVERLAP_MULTI, \n",
    "                                     START_STOP_MULTI, data_scaler, trained_svc)\n",
    "        \n",
    "        # aggregate detections\n",
    "        self._aggregate_detections(detections)\n",
    "        \n",
    "        # increment frame number\n",
    "        self._frame_index += 1\n",
    "        \n",
    "        # if we have enough frames...\n",
    "        if self._frame_index%self._FRAME_AGGREGATE == 0:\n",
    "            # get aggregate bboxes\n",
    "            self._bbox_list_recent = bboxes_from_detections(image_, self._detection_list_total,\n",
    "                                                            self._threshold)\n",
    "            # reset the detections\n",
    "            self._detection_list_total = None   #reset system\n",
    "\n",
    "        # if we have bboxes... \n",
    "        if self._bbox_list_recent is not None:\n",
    "            # draw them\n",
    "            image_ = draw_detections(image_, self._bbox_list_recent, (0,0,255))\n",
    "        \n",
    "        return image_\n",
    "\n",
    "    \n",
    "print('Success: VideoProcessor class defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_video(input_filename_, output_filename_, subclip_=None):\n",
    "    # Grab the video\n",
    "    if subclip_ is None:\n",
    "        clip = VideoFileClip(input_filename_)\n",
    "    else: \n",
    "        clip = VideoFileClip(input_filename_).subclip(subclip_[0],subclip_[1])\n",
    "    \n",
    "    # Process the frames\n",
    "    video_processor = VideoProcessor()\n",
    "    \n",
    "    processed_clip = clip.fl_image(video_processor.process_image)\n",
    "\n",
    "    # Save the video\n",
    "    %time processed_clip.write_videofile(output_filename_, audio=False)\n",
    "\n",
    "    \n",
    "print('Success: process_video() function defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Test Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_video('test_video.mp4', 'test_video_soln.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "video = io.open('test_video_soln.mp4', 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_video('project_video.mp4', 'project_video_soln.mp4')\n",
    "#process_video('project_video.mp4', 'project_video_soln.mp4', subclip_=(10,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "video = io.open('project_video_soln.mp4', 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
