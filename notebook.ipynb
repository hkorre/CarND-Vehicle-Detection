{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection and Tracking\n",
    "\n",
    "---\n",
    "By Hasan Korre\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "* Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "* Apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector. Retrain your classifier and hopefully see improved accuracy.\n",
    "  * Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "* Using a Decision Tree classifier, explore the feature importances and consider pruning or adding new features.\n",
    "* Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "* Run your pipeline on a video stream and implement tracking to follow detected vehicles.\n",
    "* Create a heat map of recurring detections frame by frame to reject outliers.\n",
    "* Estimate a bounding box for vehicles detected.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "from random import randint\n",
    "from sklearn import tree\n",
    "from skimage.feature import blob_doh, corner_peaks, hog\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.morphology import watershed\n",
    "from scipy import ndimage as ndi\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('Success: Imported libraries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicles Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in example images\n",
    "img_vehicle_far = imread('vehicles/GTI_Far/image0000.png')\n",
    "img_vehicle_left = imread('vehicles/GTI_Left/image0009.png')\n",
    "img_vehicle_middle = imread('vehicles/GTI_MiddleClose/image0000.png')\n",
    "img_vehicle_right = imread('vehicles/GTI_Right/image0000.png')\n",
    "img_vehicle_kitti = imread('vehicles/KITTI_extracted/1.png')\n",
    "\n",
    "print('img shape = ', img_vehicle_far.shape)\n",
    "train_height = img_vehicle_far.shape[0]\n",
    "train_width = img_vehicle_far.shape[1]\n",
    "train_channels = img_vehicle_far.shape[2]\n",
    "\n",
    "# Display\n",
    "f1, (a11, a12, a13, a14, a15) = plt.subplots(1, 5, figsize=(8, 6))\n",
    "f1.tight_layout()\n",
    "a11.imshow(img_vehicle_far)\n",
    "a11.set_title('Vehicle - Far', fontsize=10)\n",
    "a12.imshow(img_vehicle_left)\n",
    "a12.set_title('Vehicle - Left', fontsize=10)\n",
    "a13.imshow(img_vehicle_middle)\n",
    "a13.set_title('Vehicle - Middle', fontsize=10)\n",
    "a14.imshow(img_vehicle_right)\n",
    "a14.set_title('Vehicle - Right', fontsize=10)\n",
    "a15.imshow(img_vehicle_kitti)\n",
    "a15.set_title('Vehicle - Kitti', fontsize=10)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Vehicle Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in example images\n",
    "img_nonVehicle_gti1 = imread('non-vehicles/GTI/image1.png')\n",
    "img_nonVehicle_gti3000 = imread('non-vehicles/GTI/image3000.png')\n",
    "img_nonVehicle_gti700 = imread('non-vehicles/GTI/image700.png')\n",
    "img_nonVehicle_extra1 = imread('non-vehicles/Extras/extra1.png')\n",
    "img_nonVehicle_extra5000 = imread('non-vehicles/Extras/extra5000.png')\n",
    "\n",
    "# Display\n",
    "f1, (a11, a12, a13, a14, a15) = plt.subplots(1, 5, figsize=(8, 6))\n",
    "f1.tight_layout()\n",
    "a11.imshow(img_nonVehicle_gti1)\n",
    "a11.set_title('NonVehicle - GTI 1', fontsize=10)\n",
    "a12.imshow(img_nonVehicle_gti3000)\n",
    "a12.set_title('NonVehicle - GTI 3000', fontsize=10)\n",
    "a13.imshow(img_nonVehicle_gti700)\n",
    "a13.set_title('NonVehicle - GTI 700', fontsize=10)\n",
    "a14.imshow(img_nonVehicle_extra1)\n",
    "a14.set_title('NonVehicle - Extra 1', fontsize=10)\n",
    "a15.imshow(img_nonVehicle_extra5000)\n",
    "a15.set_title('NonVehicle - Extra 5000', fontsize=10)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lists of image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_filenames_to_list(list_, filenames_):\n",
    "    for filename in filenames_:\n",
    "        list_.append(filename)\n",
    "\n",
    "# Vehicles\n",
    "car_filepaths = []\n",
    "car_directories = ['vehicles/GTI_Far/',\n",
    "                   'vehicles/GTI_Left/',\n",
    "                   'vehicles/GTI_MiddleClose/',\n",
    "                   'vehicles/GTI_Right/',\n",
    "                   'vehicles/KITTI_extracted/']\n",
    "for folder in car_directories:\n",
    "    glob_filenames = glob.glob(folder + '*.png')\n",
    "    add_filenames_to_list(car_filepaths, glob_filenames)\n",
    "\n",
    "\n",
    "# Non-Vehicles\n",
    "notcar_filepaths = []\n",
    "notcar_directories = ['non-vehicles/GTI/',\n",
    "                      'non-vehicles/Extras/']\n",
    "for folder in notcar_directories:\n",
    "    glob_filenames = glob.glob(folder + '*.png')\n",
    "    add_filenames_to_list(notcar_filepaths, glob_filenames)\n",
    "\n",
    "\n",
    "print('# car_filepaths = {}'.format(len(car_filepaths)))\n",
    "print('# notcar_filepaths = {}'.format(len(notcar_filepaths)))\n",
    "print('Success: Created image name lists.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to return HOG features vector and visualization\n",
    "def get_hog_features(img_, orient_, pix_per_cell_, cell_per_block_, vis_=False):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis_ == True:\n",
    "        features, hog_image = hog(img_, orientations=orient_, pixels_per_cell=(pix_per_cell_, pix_per_cell_),\n",
    "                                  cells_per_block=(cell_per_block_, cell_per_block_), transform_sqrt=True, \n",
    "                                  visualise=vis_, feature_vector=True)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img_, orientations=orient_, pixels_per_cell=(pix_per_cell_, pix_per_cell_),\n",
    "                       cells_per_block=(cell_per_block_, cell_per_block_), transform_sqrt=True, \n",
    "                       visualise=vis_, feature_vector=True)\n",
    "        return features\n",
    "\n",
    "\n",
    "'''\n",
    "test it...\n",
    "'''\n",
    "PIX_PER_CELL = 8\n",
    "CELL_PER_BLOCK = 2\n",
    "ORIENT = 9\n",
    "\n",
    "hog_test_img = imread('vehicles/GTI_Left/image0009.png')\n",
    "hog_test_gray = cv2.cvtColor(hog_test_img, cv2.COLOR_RGB2GRAY)\n",
    "features, hog_test_result = get_hog_features(hog_test_gray, ORIENT, PIX_PER_CELL, CELL_PER_BLOCK, vis_=True)\n",
    "\n",
    "# Display\n",
    "f1, (a11, a12) = plt.subplots(1, 2, figsize=(4, 3))\n",
    "f1.tight_layout()\n",
    "a11.imshow(hog_test_img)\n",
    "a11.set_title('Test Image', fontsize=10)\n",
    "a12.imshow(hog_test_result, cmap='gray')\n",
    "a12.set_title('HOG Image', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to extract features from a list of images\n",
    "#   uses Lab color space and only hog features\n",
    "def extract_features(img_, spatial_size_=(32, 32),\n",
    "                           hist_bins_=32, hist_range_=(0, 256), orient_=9, \n",
    "                           pix_per_cell_=8, cell_per_block_=2):\n",
    "    # apply color conversion\n",
    "    img_lab = cv2.cvtColor(img_, cv2.COLOR_RGB2Lab) \n",
    "    # create feature vectors\n",
    "    hog_features_0 = get_hog_features(img_lab[:,:,0], orient_, \n",
    "            pix_per_cell_, cell_per_block_, vis_=False)\n",
    "    hog_features_1 = get_hog_features(img_lab[:,:,1], orient_, \n",
    "            pix_per_cell_, cell_per_block_, vis_=False)\n",
    "    hog_features_2 = get_hog_features(img_lab[:,:,2], orient_, \n",
    "            pix_per_cell_, cell_per_block_, vis_=False)\n",
    "    # concat features\n",
    "    return np.concatenate((hog_features_0, hog_features_1, hog_features_2))\n",
    "\n",
    "\n",
    "# Define a function to extract features from a list of images\n",
    "def extract_features_files(filepaths_, spatial_size_=(32, 32),\n",
    "                           hist_bins_=32, hist_range_=(0, 256), orient_=9, \n",
    "                           pix_per_cell_=8, cell_per_block_=2):\n",
    "    features_list = []   #list to append feature vectors to\n",
    "    for filepath in filepaths_:\n",
    "        image = imread(filepath)\n",
    "        #image = image.astype(np.float32)\n",
    "        features_single = extract_features(image, spatial_size_,\n",
    "                           hist_bins_, hist_range_, orient_, \n",
    "                           pix_per_cell_, cell_per_block_)\n",
    "        \n",
    "        if np.isnan(features_single).any():\n",
    "            print(filepath)\n",
    "        \n",
    "        features_list.append(features_single)\n",
    "    return features_list\n",
    "\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "# find features\n",
    "print('Extracting car features...')\n",
    "car_features = extract_features_files(car_filepaths, orient_=ORIENT, \n",
    "                                      pix_per_cell_=PIX_PER_CELL, \n",
    "                                      cell_per_block_=CELL_PER_BLOCK)\n",
    "print('Extracting non-car features...')\n",
    "notcar_features = extract_features_files(notcar_filepaths, orient_=ORIENT, \n",
    "                                         pix_per_cell_=PIX_PER_CELL, \n",
    "                                         cell_per_block_=CELL_PER_BLOCK)\n",
    "print('Features found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_features(car_features_, notcar_features_):    \n",
    "    # Create an array stack of feature vectors\n",
    "    X = np.vstack((car_features_, notcar_features_)).astype(np.float64)\n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Get mean=0 and variance=1\n",
    "    return X_scaler.transform(X), X_scaler\n",
    "\n",
    "# Define the labels vector\n",
    "def create_labels(car_features_, notcar_features_):\n",
    "    return np.hstack((np.ones(len(car_features_)), np.zeros(len(notcar_features_))))\n",
    "\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "scaled_features, data_scaler = preprocess_features(car_features, notcar_features)\n",
    "total_labels = create_labels(car_features, notcar_features)\n",
    "\n",
    "print('scaled_features.shape = ', scaled_features.shape)\n",
    "print('total_labels.shape = ', total_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split up data into randomized training and test sets\n",
    "def split_test_and_train(X_, Y_, test_size_=0.2):\n",
    "    start_rand = np.random.randint(0, 100)\n",
    "    X_train, X_test, Y_train, Y_test = \\\n",
    "      train_test_split(X_, Y_, test_size=test_size_, random_state=start_rand)\n",
    "    return (X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "# Calibrated Linear Support-Vector-Classifier\n",
    "def train_svc(X_train_, X_test_, Y_train_, Y_test_, c_=1.0):\n",
    "    # setup linear support-vector-classifier\n",
    "    svc = LinearSVC(C=c_)\n",
    "    # setup and train calibrated classifier\n",
    "    cal_svc = CalibratedClassifierCV(svc)\n",
    "    cal_svc.fit(X_train_, Y_train_)\n",
    "    # Check the score of the classifier\n",
    "    print('Train Accuracy of SVC = ', cal_svc.score(X_train_, Y_train_))\n",
    "    print('Test Accuracy of SVC = ', cal_svc.score(X_test_, Y_test_))\n",
    "    return cal_svc\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "  split_test_and_train(scaled_features, total_labels)\n",
    "print('Split data.')\n",
    "trained_svc = train_svc(x_train, x_test, y_train, y_test, 1000.0)\n",
    "print('Trained SVC.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_boxes(img_, bboxes_, color_=(0, 0, 255), thick_=6):\n",
    "    img_copy = np.copy(img_)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes_:\n",
    "        cv2.rectangle(img_copy, bbox[0], bbox[1], color_, thick_)\n",
    "    return img_copy\n",
    "\n",
    "# Define a function that takes an image,\n",
    "#   start and stop positions in both x and y, \n",
    "#   window size (x and y dimensions),  \n",
    "#   and overlap fraction (for both x and y)\n",
    "def slide_window(img_, x_start_stop_=[None, None], y_start_stop_=[None, None], \n",
    "                    xy_window_=(64, 64), xy_overlap_=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop_[0] == None:\n",
    "        x_start_stop_[0] = 0\n",
    "    if x_start_stop_[1] == None:\n",
    "        x_start_stop_[1] = img_.shape[1]\n",
    "    if y_start_stop_[0] == None:\n",
    "        y_start_stop_[0] = 0\n",
    "    if y_start_stop_[1] == None:\n",
    "        y_start_stop_[1] = img_.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop_[1] - x_start_stop_[0]\n",
    "    yspan = y_start_stop_[1] - y_start_stop_[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window_[0]*(1 - xy_overlap_[0]))\n",
    "    ny_pix_per_step = np.int(xy_window_[1]*(1 - xy_overlap_[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_windows = np.int(xspan/nx_pix_per_step) - 1\n",
    "    ny_windows = np.int(yspan/ny_pix_per_step) - 1\n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop_[0]\n",
    "            endx = startx + xy_window_[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop_[0]\n",
    "            endy = starty + xy_window_[1]\n",
    "            # window limits\n",
    "            startx = 0 if startx < 0 else startx\n",
    "            endx = img_.shape[1] if endx > img_.shape[1] else endx\n",
    "            starty = 0 if starty < 0 else starty\n",
    "            endy = img_.shape[0] if endy > img_.shape[0] else endy\n",
    "            # Append window position to list\n",
    "            if (endx-startx == xy_window_[0]) and (endy-starty == xy_window_[1]):\n",
    "                window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "\n",
    "'''\n",
    "test it...\n",
    "'''\n",
    "TEST_IMG = imread('test_images/test1.jpg')\n",
    "TEST_IMG = cv2.resize(TEST_IMG, (960,540))\n",
    "WINDOW_SIZE = (256, 256) #(64,64) #(128,128)\n",
    "OVERLAP = (0.8,0.8)\n",
    "Y_START_STOP = [int(TEST_IMG.shape[0]/2), None]\n",
    "test_windows = slide_window(TEST_IMG, \n",
    "                            x_start_stop_=[None, None], y_start_stop_=Y_START_STOP, \n",
    "                            xy_window_=WINDOW_SIZE, xy_overlap_=OVERLAP)\n",
    "img_windows = draw_boxes(TEST_IMG, test_windows, color_=(0, 0, 255), thick_=6)\n",
    "plt.imshow(img_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_cars(img_, window_list_, window_size_, scaler_, classifier_):\n",
    "    img_window = np.zeros(window_size_)\n",
    "    num_detections = 0\n",
    "    window_list_detections = []\n",
    "    # for each window...\n",
    "    for bbox in window_list_:\n",
    "        # extract part of img_\n",
    "        top_L_x = bbox[0][0]\n",
    "        top_L_y = bbox[0][1]\n",
    "        bot_R_x = bbox[1][0]\n",
    "        bot_R_y = bbox[1][1]\n",
    "        img_window = img_[top_L_y:bot_R_y,top_L_x:bot_R_x,:]\n",
    "        # resize to 64x64\n",
    "        img_resized = cv2.resize(img_window, (train_height,train_width))\n",
    "        # extract features\n",
    "        features = extract_features(img_resized, orient_=ORIENT, \n",
    "                                    pix_per_cell_=PIX_PER_CELL, cell_per_block_=CELL_PER_BLOCK)\n",
    "        features = features.reshape(1, -1)   #stop the executor from complaining\n",
    "        # preprocess features\n",
    "        scaled_features = scaler_.transform(features)\n",
    "        # predict with svc\n",
    "        prediction = classifier_.predict(scaled_features)\n",
    "        prediction_prob_1 = classifier_.predict_proba(scaled_features)[0][1]\n",
    "        if prediction == 1 and prediction_prob_1 > 0.75:\n",
    "            window_list_detections.append(bbox)\n",
    "            num_detections += 1\n",
    "\n",
    "    #print('{} detections.'.format(num_detections))\n",
    "    return window_list_detections\n",
    "\n",
    "# map the inputs to the function blocks\n",
    "color_dict = {0: (255,   0,   0),  #red\n",
    "              1: (  0, 255,   0),  #green\n",
    "              2: (  0,   0, 255),  #blue\n",
    "              3: (255, 255,   0),  #yellow\n",
    "              4: (255,   0, 255),  #purple\n",
    "              5: (255, 140,   0)   #orange\n",
    "}\n",
    "\n",
    "def draw_detections(img_, detections_list_, draw_color_=None):\n",
    "    if draw_color_ is None:\n",
    "        draw_color_ = color_dict[randint(0,5)]\n",
    "    return draw_boxes(img_, detections_list_, color_=draw_color_)\n",
    "\n",
    "\n",
    "'''\n",
    "test it...\n",
    "'''\n",
    "detections_list = find_cars(TEST_IMG, test_windows, WINDOW_SIZE, data_scaler, trained_svc)\n",
    "img_boxed_cars = draw_detections(TEST_IMG, detections_list)\n",
    "plt.imshow(img_boxed_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find cars with different size windows\n",
    "def find_cars_multiSize(img_, window_sizes_, overlaps_, scaler_, classifier_):\n",
    "    detections_list_total = []\n",
    "    #for size in window_sizes_:\n",
    "    for size, overlap in zip(window_sizes_, overlaps_):\n",
    "        windows = slide_window(img_, x_start_stop_=[None, None], y_start_stop_=Y_START_STOP, \n",
    "                               xy_window_=size, xy_overlap_=overlap)\n",
    "        detections_list = find_cars(img_, windows, size, scaler_, classifier_)\n",
    "        detections_list_total = detections_list_total + detections_list\n",
    "    return detections_list_total\n",
    "\n",
    "def findAndDraw_cars_multiSize(img_, window_sizes_, overlaps_, scaler_, classifier_):\n",
    "    detections = find_cars_multiSize(img_, window_sizes_, overlaps_, scaler_, classifier_)\n",
    "    return draw_detections(np.copy(img_), detections)    \n",
    "    \n",
    "'''\n",
    "test it...\n",
    "'''\n",
    "WINDOW_SIZES_MULTI = [(64,64),(128,128)]\n",
    "OVERLAP_MULTI = [(0.65,0.65),(0.75,0.75)]\n",
    "img_detect_cars = findAndDraw_cars_multiSize(TEST_IMG, WINDOW_SIZES_MULTI, OVERLAP_MULTI, data_scaler, trained_svc)\n",
    "plt.imshow(img_detect_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def detect_on_test_images(img_names_, window_sizes_, overlaps_, scaler_, classifier_):\n",
    "    is_left = True\n",
    "    for index, name in enumerate(img_names_):\n",
    "        print(name)\n",
    "        image = imread('test_images/' + name)\n",
    "    \n",
    "        image = findAndDraw_cars_multiSize(image, window_sizes_, overlaps_, scaler_, classifier_)\n",
    "    \n",
    "        if is_left:\n",
    "            fig = plt.figure(figsize=(8, 6))\n",
    "            a=fig.add_subplot(1,2,1)\n",
    "            is_left = False\n",
    "        else:    \n",
    "            a=fig.add_subplot(1,2,2)\n",
    "            is_left = True\n",
    "        a.set_title(name)\n",
    "        plt.imshow(image)\n",
    "        \n",
    "'''\n",
    "test it...\n",
    "'''\n",
    "IMG_NAMES = os.listdir('test_images/')\n",
    "detect_on_test_images(IMG_NAMES, WINDOW_SIZES_MULTI, OVERLAP_MULTI, data_scaler, trained_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEST_IMG = imread('test_images/challenge_7.jpg')\n",
    "TEST_IMG = cv2.resize(TEST_IMG, (960,540))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Heat Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test udacity suggested code\n",
    "\n",
    "def add_heat(heatmap_, bbox_list_):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list_:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap_[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap_\n",
    "\n",
    "def apply_threshold(heatmap_, threshold_):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap_[heatmap_ < threshold_] = 0\n",
    "    heatmap_[heatmap_ > 0] = 1\n",
    "    return heatmap_\n",
    "\n",
    "def bbox_from_labels(labels_):\n",
    "    bbox_list = []\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels_[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels_[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        bbox_list.append(bbox)        \n",
    "    return bbox_list\n",
    "\n",
    "def bboxes_from_detections(img_, detections_, threshold_):\n",
    "    heatmap = np.zeros((img_.shape[0],img_.shape[1]))\n",
    "    heatmap = add_heat(heatmap, detections_)\n",
    "    heatmap = apply_threshold(heatmap, threshold_)\n",
    "    labels = label(heatmap)\n",
    "    return bbox_from_labels(labels) \n",
    "\n",
    "\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "'''\n",
    "Test it...\n",
    "'''\n",
    "detections_for_heatmap = find_cars_multiSize(TEST_IMG, WINDOW_SIZES_MULTI, OVERLAP_MULTI, data_scaler, trained_svc)\n",
    "combined_boxes = bboxes_from_detections(TEST_IMG, detections_for_heatmap, 1)\n",
    "img_combined_box = draw_detections(TEST_IMG, combined_boxes)\n",
    "plt.imshow(img_combined_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_heatmap(img_, windows_list_, shading_):\n",
    "    img_copy = np.zeros((img_.shape[0],img_.shape[1]), dtype=np.float32)\n",
    "    for bbox in windows_list_:\n",
    "        # draw box filled in\n",
    "        leftX = bbox[0][0]\n",
    "        topY = bbox[0][1]\n",
    "        rightX = bbox[1][0]\n",
    "        bottomY = bbox[1][1]\n",
    "        img_copy[topY:bottomY, leftX:rightX] += shading_\n",
    "    # Keep 8bit\n",
    "    img_copy[img_copy[:,:]>255] = 255\n",
    "    \n",
    "    return img_copy.astype(np.uint8)\n",
    "\n",
    "def heatmap_threshold(heatmap_, threshold_):\n",
    "    img_copy = np.copy(heatmap_)\n",
    "    # Zero out pixels below the threshold\n",
    "    img_copy[img_copy <= threshold_] = 0\n",
    "    return img_copy\n",
    "\n",
    "'''\n",
    "Test it...\n",
    "'''\n",
    "detections_for_heatmap = find_cars_multiSize(TEST_IMG, WINDOW_SIZES_MULTI, OVERLAP_MULTI, data_scaler, trained_svc)\n",
    "img_heatmap = create_heatmap(TEST_IMG, detections_for_heatmap, 1)\n",
    "img_heatmap_threshold = heatmap_threshold(img_heatmap, 1)\n",
    "\n",
    "# Display\n",
    "f1, (a11, a12) = plt.subplots(1, 2, figsize=(8, 6))\n",
    "f1.tight_layout()\n",
    "a11.imshow(img_heatmap, cmap='gray')\n",
    "a11.set_title('Original Heatmap', fontsize=10)\n",
    "a12.imshow(img_heatmap_threshold, cmap='gray')\n",
    "a12.set_title('Thresholded Heatmap', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blob Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def binary_8bit(img_):\n",
    "    img_copy = np.copy(img_)\n",
    "    img_copy[img_copy>0] = 255\n",
    "    return img_copy\n",
    "\n",
    "#def blob_detection(heatmap_, max_sigma_=200, num_sigma_=10, threshold_=0.005):\n",
    "def blob_detection(heatmap_, max_sigma_=100, num_sigma_=10, threshold_=0.01):\n",
    "    img_copy = np.copy(binary_8bit(heatmap_))\n",
    "    try:\n",
    "        return blob_doh(img_copy, max_sigma=max_sigma_, num_sigma=num_sigma_, threshold=threshold_)\n",
    "    except IndexError:\n",
    "        return np.array([])\n",
    "\n",
    "'''\n",
    "Test it...\n",
    "'''\n",
    "blobs_generated = blob_detection(img_heatmap_threshold)\n",
    "print(blobs_generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# based on http://scikit-image.org/docs/dev/auto_examples/plot_watershed.html\n",
    "def segmentation(img_, min_distance_=30):\n",
    "    img_copy = np.copy(img_)\n",
    "    # Generate the markers as local maxima of the distance to the background\n",
    "    distance = ndi.distance_transform_edt(img_copy)\n",
    "    local_maxi = corner_peaks(distance, min_distance=min_distance_, \n",
    "                              indices=False, footprint=np.ones((3, 3)))\n",
    "    markers = ndi.label(local_maxi)[0]\n",
    "    labels = watershed(-distance, markers, mask=img_copy)\n",
    "    return distance, labels\n",
    "\n",
    "'''\n",
    "Test it...\n",
    "'''\n",
    "img_distance, img_segmented = segmentation(img_heatmap)\n",
    "\n",
    "# Display\n",
    "f1, (a11, a12, a13) = plt.subplots(1, 3, figsize=(10, 6))\n",
    "f1.tight_layout()\n",
    "a11.imshow(img_heatmap, cmap='gray')\n",
    "a11.set_title('Heatmap', fontsize=10)\n",
    "a12.imshow(-img_distance, cmap='gray')\n",
    "a12.set_title('Inv Distance', fontsize=10)\n",
    "a13.imshow(img_segmented, cmap='gray')\n",
    "a13.set_title('Image Segmented', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blob Detection and Segmentation together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## blob then watershed\n",
    "def bbox_from_blob_and_seg(blobs_generated_, img_segmented_):\n",
    "    bbox_list = []\n",
    "    for entry in range(blobs_generated_.shape[0]):\n",
    "        blob_row = int(blobs_generated_[entry][0])\n",
    "        blob_col = int(blobs_generated_[entry][1])\n",
    "        segment_value = img_segmented_[blob_row, blob_col]\n",
    "        # if not background...\n",
    "        if segment_value != 0:\n",
    "            # find left and right bounds\n",
    "            row = img_segmented_[blob_row, :]\n",
    "            row_extent = np.where(row == segment_value)[0]\n",
    "            leftX = row_extent[0]\n",
    "            rightX = row_extent[-1]\n",
    "            # find top and bottom bounds\n",
    "            col = img_segmented_[:, blob_col]\n",
    "            col_extent = np.where(col == segment_value)[0]\n",
    "            topY = col_extent[0]\n",
    "            bottomY = col_extent[-1]\n",
    "            # add new bbox\n",
    "            new_bbox = ((leftX, topY), (rightX, bottomY))\n",
    "            bbox_list.append(new_bbox)\n",
    "        \n",
    "    return bbox_list\n",
    "\n",
    "\n",
    "'''\n",
    "Test it...\n",
    "'''\n",
    "combined_boxes = bbox_from_blob_and_seg(blobs_generated, img_segmented)\n",
    "img_combined_box = draw_detections(TEST_IMG, combined_boxes)\n",
    "\n",
    "plt.imshow(img_combined_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bound_test_images(img_names_, window_sizes_, overlap_, scaler_, classifier_):\n",
    "    is_left = True\n",
    "    for index, name in enumerate(img_names_):\n",
    "        print(name)\n",
    "        image = imread('test_images/' + name)\n",
    "        image = cv2.resize(image, (960,540))\n",
    "        \n",
    "        detections = find_cars_multiSize(image, window_sizes_, overlap_, scaler_, classifier_)\n",
    "        if len(detections) != 0:\n",
    "            '''\n",
    "            # create heatmaps\n",
    "            img_heatmap = create_heatmap(image, detections, 1)\n",
    "            ##img_heatmap_threshold = heatmap_threshold(img_heatmap, 1)\n",
    "            # blob detection\n",
    "            blobs_generated = blob_detection(img_heatmap_threshold)\n",
    "            # segmentation\n",
    "            _, img_segmented = segmentation(img_heatmap)\n",
    "            # combine\n",
    "            combined_boxes = bbox_from_blob_and_seg(blobs_generated, img_segmented)\n",
    "            '''\n",
    "            combined_boxes = bboxes_from_detections(TEST_IMG, detections, 1)\n",
    "            image = draw_detections(image, combined_boxes)\n",
    "\n",
    "        # display\n",
    "        if is_left:\n",
    "            fig = plt.figure(figsize=(8, 6))\n",
    "            a=fig.add_subplot(1,2,1)\n",
    "            is_left = False\n",
    "        else:    \n",
    "            a=fig.add_subplot(1,2,2)\n",
    "            is_left = True\n",
    "        a.set_title(name)\n",
    "        plt.imshow(image)\n",
    "        \n",
    "'''\n",
    "test it...\n",
    "'''\n",
    "IMG_NAMES = os.listdir('test_images/')\n",
    "bound_test_images(IMG_NAMES, WINDOW_SIZES_MULTI, OVERLAP_MULTI, data_scaler, trained_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard-Negative Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run if not done already..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# $ mkdir non-vehicles/false_positives\n",
    "\n",
    "from matplotlib import interactive\n",
    "interactive(True)\n",
    "\n",
    "def check_false_positive(img_windowed_, name_):\n",
    "    false_positive_num = 0\n",
    "    plt.imshow(img_windowed_)\n",
    "    plt.show()\n",
    "    is_detection = bool(int(input(\"Is this a real detection (0,1): \")))\n",
    "    print (\"you entered...\", is_detection)\n",
    "    if not is_detection:\n",
    "        filename = 'non-vehicles/false_positives/' + name_ + '_' + str(false_positive_num) + '.png'\n",
    "        imsave(filename, img_windowed_)\n",
    "        print('saved as {}'.format(filename))\n",
    "        false_positive_num += 1     \n",
    "\n",
    "def find_cars_review(img_, window_list_, window_size_, scaler_, classifier_):\n",
    "    rand_color = color_dict[randint(0,5)]\n",
    "    imcopy = np.copy(img_)\n",
    "    img_window = np.zeros(window_size_)\n",
    "    num_detections = 0\n",
    "    window_list_detections = []\n",
    "    # for each window...\n",
    "    bbox_num = 0\n",
    "    for bbox in window_list_:\n",
    "        # extract part of img_\n",
    "        top_L_x = bbox[0][0]\n",
    "        top_L_y = bbox[0][1]\n",
    "        bot_R_x = bbox[1][0]\n",
    "        bot_R_y = bbox[1][1]\n",
    "        img_window = img_[top_L_y:bot_R_y,top_L_x:bot_R_x,:]\n",
    "        # resize to 64x64\n",
    "        img_resized = cv2.resize(img_window, (train_height, train_width))\n",
    "        # extract features\n",
    "        features = extract_features(img_resized, orient_=ORIENT, \n",
    "                                    pix_per_cell_=PIX_PER_CELL, cell_per_block_=CELL_PER_BLOCK)\n",
    "        features = features.reshape(1, -1)   #stop the executor from complaining\n",
    "        # preprocess features\n",
    "        scaled_features = scaler_.transform(features)\n",
    "        # predict with svc\n",
    "        if classifier_.predict(scaled_features) == 1:\n",
    "            window_list_detections.append(bbox)\n",
    "            num_detections += 1\n",
    "            check_false_positive(img_resized, 'bbox'+str(bbox_num))\n",
    "        bbox_num += 1\n",
    "\n",
    "    print('{} detections.'.format(num_detections))\n",
    "    return window_list_detections \n",
    "\n",
    "def find_cars_multiSize_review(img_, window_sizes_, scaler_, classifier_):\n",
    "    imcopy = np.copy(img_)\n",
    "    window_detections_list_total = []\n",
    "    for size in window_sizes_:\n",
    "        #print('detecting in window size {}...'.format(size))\n",
    "        windows = slide_window(imcopy, x_start_stop_=[None, None], y_start_stop_=Y_START_STOP, \n",
    "                    xy_window_=size, xy_overlap_=OVERLAP)\n",
    "        window_detections_list = find_cars_review(imcopy, windows, WINDOW_SIZE, \n",
    "                                                  scaler_, classifier_)\n",
    "        window_detections_list_total = window_detections_list_total + window_detections_list\n",
    "    imcopy = print_bboxes(img_, window_detections_list_total) \n",
    "    return imcopy\n",
    "\n",
    "\n",
    "'''\n",
    "Let's try it...\n",
    "'''\n",
    "is_left = True\n",
    "img_names = os.listdir('test_images/')\n",
    "\n",
    "for index, name in enumerate(img_names):\n",
    "    image = imread('test_images/' + name)\n",
    "    image = find_cars_multiSize_review(image, WINDOW_SIZES_MULTI, OVERLAP_MULTI, data_scaler, trained_svc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get new list of non-vehicle images\n",
    "notcar_filepaths = []\n",
    "notcar_directories = ['non-vehicles/GTI/',\n",
    "                      'non-vehicles/Extras/',\n",
    "                      'non-vehicles/false_positives/']\n",
    "for folder in notcar_directories:\n",
    "    glob_filenames = glob.glob(folder + '*.png')\n",
    "    add_filenames_to_list(notcar_filepaths, glob_filenames)\n",
    "\n",
    "\n",
    "print('# car_filepaths = {}'.format(len(car_filepaths)))\n",
    "print('# notcar_filepaths = {}'.format(len(notcar_filepaths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# retrain...\n",
    "car_features = extract_features_files(car_filepaths, orient_=ORIENT,\n",
    "                                      pix_per_cell_=PIX_PER_CELL, \n",
    "                                      cell_per_block_=CELL_PER_BLOCK)\n",
    "notcar_features = extract_features_files(notcar_filepaths, orient_=ORIENT, \n",
    "                                         pix_per_cell_=PIX_PER_CELL, \n",
    "                                         cell_per_block_=CELL_PER_BLOCK)\n",
    "print('Features found.')\n",
    "\n",
    "# preproces data (redo on color space)\n",
    "scaled_features, data_scaler = preprocess_features(car_features, notcar_features)\n",
    "total_labels = create_labels(car_features, notcar_features)\n",
    "print('Data preprocessed.')\n",
    "\n",
    "# split and train (redo on color space)\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "  split_test_and_train(scaled_features, total_labels)\n",
    "trained_svc = train_svc(x_train, x_test, y_train, y_test, 1000.0)\n",
    "print('SVC trained.')\n",
    "\n",
    "# find the cars\n",
    "detect_on_test_images(IMG_NAMES, WINDOW_SIZES_MULTI, OVERLAP_MULTI, data_scaler, trained_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bound_test_images(IMG_NAMES, WINDOW_SIZES_MULTI, OVERLAP_MULTI, data_scaler, trained_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Grab Frame from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grab_video_frame(filepath_, frame_):\n",
    "    clip = VideoFileClip(filepath_)\n",
    "    return clip.get_frame(frame_)\n",
    "\n",
    "# image should be RGB\n",
    "def save_image(img_, filepath_):\n",
    "    mpimg.imsave(filepath_, img_)\n",
    "\n",
    "\n",
    "## try it ######\n",
    "frame_num = 6\n",
    "test_frame = grab_video_frame('solidWhiteRight.mp4', frame_num)\n",
    "plt.imshow(test_frame)\n",
    "\n",
    "'''\n",
    "SAVE_FOLDER = 'test_images/'\n",
    "save_name = SAVE_FOLDER + 'challenge_{}.jpg'.format(frame_num)\n",
    "save_image(test_frame, save_name)\n",
    "'''\n",
    "\n",
    "print('Success: Defined functions to grab video frames.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pipeline\n",
    "# expects 960*540 video\n",
    "def process_image(image_):\n",
    "    detections = find_cars_multiSize(image_, WINDOW_SIZES_MULTI, OVERLAP_MULTI, data_scaler, trained_svc)\n",
    "    if len(detections) != 0:\n",
    "        '''\n",
    "        # create heatmaps\n",
    "        img_heatmap = create_heatmap(image_, detections, 1)\n",
    "        ##img_heatmap_threshold = heatmap_threshold(img_heatmap, 1)\n",
    "        # blob detection\n",
    "        blobs_generated = blob_detection(img_heatmap_threshold)\n",
    "        # segmentation\n",
    "        _, img_segmented = segmentation(img_heatmap)\n",
    "        # combine\n",
    "        combined_boxes = bbox_from_blob_and_seg(blobs_generated, img_segmented)\n",
    "        '''\n",
    "        combined_boxes = bboxes_from_detections(TEST_IMG, detections, 1)\n",
    "        image_ = draw_detections(image_, combined_boxes, (0,0,255))\n",
    "    return image_\n",
    "\n",
    "\n",
    "'''\n",
    "Test...\n",
    "'''\n",
    "test_img_processed = process_image(test_frame)\n",
    "plt.imshow(test_img_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Test Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename_prefix = 'solidWhiteRight'\n",
    "output_filename = filename_prefix + '_soln.mp4'\n",
    "#clip1 = VideoFileClip(filename_prefix + \".mp4\").subclip(0,2)\n",
    "clip1 = VideoFileClip(filename_prefix + \".mp4\")\n",
    "output_clip = clip1.fl_image(process_image)\n",
    "%time output_clip.write_videofile(output_filename, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "video = io.open(output_filename, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_filename = 'project_video_soln.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "output_clip = clip1.fl_image(process_image)\n",
    "%time output_clip.write_videofile(output_filename, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "video = io.open(output_filename, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train and Test Linear SVM classifier on HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract HOG features from a list of images\n",
    "def extract_features_hogOnly(filepaths_, orient_=9, pix_per_cell_=8, cell_per_block_=2):\n",
    "    features = []   #list to append feature vectors to\n",
    "    for filepath in filepaths_:\n",
    "        image = imread(filepath)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        hog_features = get_hog_features(gray, orient_, pix_per_cell_, cell_per_block_, vis_=False)\n",
    "        features.append(hog_features)\n",
    "    return features\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "car_features = extract_features_hogOnly(car_filepaths, ORIENT, PIX_PER_CELL, CELL_PER_BLOCK)\n",
    "notcar_features = extract_features_hogOnly(notcar_filepaths, ORIENT, PIX_PER_CELL, CELL_PER_BLOCK)\n",
    "\n",
    "print('Success: HOG features extracted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_features(car_features_, notcar_features_):    \n",
    "    # Create an array stack of feature vectors\n",
    "    X = np.vstack((car_features_, notcar_features_)).astype(np.float64)\n",
    "    print('X')\n",
    "    print('any nan? {}'.format(np.isnan(X).any()))\n",
    "    print('any inf? {}'.format(np.isinf(X).any()))\n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Get mean=0 and variance=1\n",
    "    return X_scaler.transform(X), X_scaler\n",
    "\n",
    "# Define the labels vector\n",
    "def create_labels(car_features_, notcar_features_):\n",
    "    return np.hstack((np.ones(len(car_features_)), np.zeros(len(notcar_features_))))\n",
    "\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "scaled_features,_ = preprocess_features(car_features, notcar_features)\n",
    "total_labels = create_labels(car_features, notcar_features)\n",
    "\n",
    "print('scaled_features.shape = ', scaled_features.shape)\n",
    "print('total_labels.shape = ', total_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split up data into randomized training and test sets\n",
    "def split_test_and_train(X_, Y_, test_size_=0.2):\n",
    "    start_rand = np.random.randint(0, 100)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_, Y_, test_size=test_size_, random_state=start_rand)\n",
    "    return (X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "# Linear Support Vector Classification\n",
    "def train_linear_svc(X_train_, X_test_, Y_train_, Y_test_, c_=1.0):\n",
    "    svc = LinearSVC(C=c_)\n",
    "    svc.fit(X_train_, Y_train_)\n",
    "    # Check the score of the SVC\n",
    "    print('Train Accuracy of SVC = ', svc.score(X_train_, Y_train_))\n",
    "    print('Test Accuracy of SVC = ', svc.score(X_test_, Y_test_))\n",
    "    return svc\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "x_train_hogOnly, x_test_hogOnly, y_train_hogOnly, y_test_hogOnly = split_test_and_train(\n",
    "    scaled_features, total_labels)\n",
    "trained_svc_hogOnly = train_linear_svc(x_train_hogOnly, x_test_hogOnly, y_train_hogOnly, y_test_hogOnly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triple HOG with Lab color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to extract features from a list of images\n",
    "def extract_features_3hog(img_, spatial_size_=(32, 32),\n",
    "                           hist_bins_=32, hist_range_=(0, 256), orient_=9, \n",
    "                           pix_per_cell_=8, cell_per_block_=2):\n",
    "    # apply color conversion\n",
    "    img_lab = cv2.cvtColor(img_, cv2.COLOR_RGB2Lab) \n",
    "    # create feature vectors\n",
    "    hog_features_0 = get_hog_features(img_lab[:,:,0], orient_, \n",
    "            pix_per_cell_, cell_per_block_, vis_=False)\n",
    "    hog_features_1 = get_hog_features(img_lab[:,:,1], orient_, \n",
    "            pix_per_cell_, cell_per_block_, vis_=False)\n",
    "    hog_features_2 = get_hog_features(img_lab[:,:,2], orient_, \n",
    "            pix_per_cell_, cell_per_block_, vis_=False)\n",
    "    # concat features\n",
    "    return np.concatenate((hog_features_0, hog_features_1, hog_features_2))\n",
    "\n",
    "\n",
    "# Define a function to extract features from a list of images\n",
    "def extract_features_3hog_files(filepaths_, spatial_size_=(32, 32),\n",
    "                           hist_bins_=32, hist_range_=(0, 256), orient_=9, \n",
    "                           pix_per_cell_=8, cell_per_block_=2):\n",
    "    features_list = []   #list to append feature vectors to\n",
    "    for filepath in filepaths_:\n",
    "        image = imread(filepath)\n",
    "        #image = image.astype(np.float32)\n",
    "        features_single = extract_features_3hog(image, spatial_size_,\n",
    "                           hist_bins_, hist_range_, orient_, \n",
    "                           pix_per_cell_, cell_per_block_)\n",
    "        \n",
    "        if np.isnan(features_single).any():\n",
    "            print(filepath)\n",
    "        \n",
    "        features_list.append(features_single)\n",
    "    return features_list\n",
    "\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "# find features\n",
    "car_features = extract_features_3hog_files(car_filepaths, orient_=ORIENT, pix_per_cell_=PIX_PER_CELL, \n",
    "                                      cell_per_block_=CELL_PER_BLOCK)\n",
    "notcar_features = extract_features_3hog_files(notcar_filepaths, orient_=ORIENT, pix_per_cell_=PIX_PER_CELL, \n",
    "                                      cell_per_block_=CELL_PER_BLOCK)\n",
    "print('Features found.')\n",
    "\n",
    "# preproces data\n",
    "scaled_features,svm_full_scaler = preprocess_features(car_features, notcar_features)\n",
    "total_labels = create_labels(car_features, notcar_features)\n",
    "print('Data preprocessed.')\n",
    "\n",
    "# split and train\n",
    "x_train_full, x_test_full, y_train_full, y_test_full = split_test_and_train(\n",
    "    scaled_features, total_labels)\n",
    "trained_svc_full = train_linear_svc(x_train_full, x_test_full, y_train_full, y_test_full)\n",
    "print('SVC trained.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Cars in Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def rand_color(index_):\n",
    "def draw_boxes(img_, bboxes_, color_=(0, 0, 255), thick_=6):\n",
    "    imcopy = np.copy(img_)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes_:\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color_, thick_)\n",
    "    return imcopy\n",
    "\n",
    "# map the inputs to the function blocks\n",
    "color_dict = {0: (255,   0,   0),  #red\n",
    "              1: (  0, 255,   0),  #green\n",
    "              2: (  0,   0, 255),  #blue\n",
    "              3: (255, 255,   0),  #yellow\n",
    "              4: (255,   0, 255),  #purple\n",
    "              5: (255, 140,   0)   #orange\n",
    "}\n",
    "\n",
    "def draw_boxes_colors(img_, bboxes_, thick_=6):\n",
    "    imcopy = np.copy(img_)\n",
    "    color = 0\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes_:        \n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color_dict[color], thick_)\n",
    "        color += 1\n",
    "        if color > 5:\n",
    "            color = 0\n",
    "    return imcopy\n",
    "\n",
    "def draw_boxes_skip1(img_, bboxes_, color_=(0, 0, 255), thick_=6):\n",
    "    imcopy = np.copy(img_)\n",
    "    # Iterate through the bounding boxes\n",
    "    is_display = True\n",
    "    for bbox in bboxes_:\n",
    "        if is_display:\n",
    "            cv2.rectangle(imcopy, bbox[0], bbox[1], color_, thick_)\n",
    "            is_display = False\n",
    "        else:\n",
    "            is_display = True\n",
    "    return imcopy\n",
    "\n",
    "# Define a function that takes an image,\n",
    "#   start and stop positions in both x and y, \n",
    "#   window size (x and y dimensions),  \n",
    "#   and overlap fraction (for both x and y)\n",
    "def slide_window(img_, x_start_stop_=[None, None], y_start_stop_=[None, None], \n",
    "                    xy_window_=(64, 64), xy_overlap_=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop_[0] == None:\n",
    "        x_start_stop_[0] = 0\n",
    "    if x_start_stop_[1] == None:\n",
    "        x_start_stop_[1] = img_.shape[1]\n",
    "    if y_start_stop_[0] == None:\n",
    "        y_start_stop_[0] = 0\n",
    "    if y_start_stop_[1] == None:\n",
    "        y_start_stop_[1] = img_.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop_[1] - x_start_stop_[0]\n",
    "    yspan = y_start_stop_[1] - y_start_stop_[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window_[0]*(1 - xy_overlap_[0]))\n",
    "    ny_pix_per_step = np.int(xy_window_[1]*(1 - xy_overlap_[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_windows = np.int(xspan/nx_pix_per_step) - 1\n",
    "    ny_windows = np.int(yspan/ny_pix_per_step) - 1\n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop_[0]\n",
    "            endx = startx + xy_window_[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop_[0]\n",
    "            endy = starty + xy_window_[1]\n",
    "            # window limits\n",
    "            startx = 0 if startx < 0 else startx\n",
    "            endx = img_.shape[1] if endx > img_.shape[1] else endx\n",
    "            starty = 0 if starty < 0 else starty\n",
    "            endy = img_.shape[0] if endy > img_.shape[0] else endy\n",
    "            # Append window position to list\n",
    "            if (endx-startx == xy_window_[0]) and (endy-starty == xy_window_[1]):\n",
    "                window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "\n",
    "\n",
    "#TODO...\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "test_img = imread('test_images/test1.jpg')\n",
    "WINDOW_SIZE = (128,128)\n",
    "#WINDOW_SIZE = (,256)\n",
    "#OVERLAP = (0.5,0.5)\n",
    "OVERLAP = (0.75,0.75)\n",
    "Y_START_STOP = [int(test_img.shape[0]/2), None]\n",
    "#Y_START_STOP = [None, None]\n",
    "test_windows = slide_window(test_img, x_start_stop_=[None, None], y_start_stop_=Y_START_STOP, \n",
    "                    xy_window_=WINDOW_SIZE, xy_overlap_=OVERLAP)\n",
    "                       \n",
    "#window_img = draw_boxes(test_img, windows, color_=(0, 0, 255), thick_=6)\n",
    "#window_img = draw_boxes_colors(test_img, windows, thick_=6)\n",
    "window_img = draw_boxes_skip1(test_img, test_windows, color_=(0, 0, 255), thick_=6)\n",
    "plt.imshow(window_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "test_img = imread('test_images/test1.jpg')\n",
    "\n",
    "def find_cars_3hog(img_, window_list_, window_size_, scaler_, classifier_):\n",
    "    img_window = np.zeros(window_size_)\n",
    "    num_detections = 0\n",
    "    window_list_detections = []\n",
    "    # for each window...\n",
    "    for bbox in window_list_:\n",
    "        #print(bbox)\n",
    "        # extract part of img_\n",
    "        top_L_x = bbox[0][0]\n",
    "        top_L_y = bbox[0][1]\n",
    "        bot_R_x = bbox[1][0]\n",
    "        bot_R_y = bbox[1][1]\n",
    "        #print('y = {}:{}'.format(top_L_y, bot_R_y))\n",
    "        #print('x = {}:{}'.format(top_L_x, bot_R_x))\n",
    "        img_window = img_[top_L_y:bot_R_y,top_L_x:bot_R_x,:]\n",
    "        # resize to 64x64\n",
    "        #print(img_window.shape)\n",
    "        img_resized = cv2.resize(img_window, (train_height,train_width))\n",
    "        # extract features\n",
    "        features = extract_features_3hog(img_resized, orient_=ORIENT, \n",
    "                                          pix_per_cell_=PIX_PER_CELL, cell_per_block_=CELL_PER_BLOCK)\n",
    "        features = features.reshape(1, -1)   #stop the executor from complaining\n",
    "        # preprocess features\n",
    "        scaled_features = scaler_.transform(features)\n",
    "        # predict with svc\n",
    "        if classifier_.predict(scaled_features) == 1:\n",
    "            window_list_detections.append(bbox)\n",
    "            num_detections += 1\n",
    "\n",
    "    print('{} detections.'.format(num_detections))\n",
    "    return window_list_detections       \n",
    "\n",
    "def print_bboxes(img_, windows_list_):\n",
    "    img_copy = np.copy(img_)\n",
    "    rand_color = color_dict[randint(0,5)]\n",
    "    for bbox in windows_list_:\n",
    "        #print('.decision_function() = {}'.format(classifier_.decision_function(scaled_features)))\n",
    "        #print('   {}'.format(bbox))\n",
    "        # draw box\n",
    "        cv2.rectangle(img_copy, bbox[0], bbox[1], rand_color, 6) \n",
    "        \n",
    "    return img_copy\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "# find features\n",
    "car_features = extract_features_3hog_files(car_filepaths, orient_=ORIENT, pix_per_cell_=PIX_PER_CELL, \n",
    "                                      cell_per_block_=CELL_PER_BLOCK)\n",
    "notcar_features = extract_features_3hog_files(notcar_filepaths, orient_=ORIENT, pix_per_cell_=PIX_PER_CELL, \n",
    "                                      cell_per_block_=CELL_PER_BLOCK)\n",
    "print('Features found.')\n",
    "\n",
    "# preproces data (redo on color space)\n",
    "scaled_features,svm_3hog_scaler = preprocess_features(car_features, notcar_features)\n",
    "total_labels = create_labels(car_features, notcar_features)\n",
    "print('Data preprocessed.')\n",
    "\n",
    "# split and train (redo on color space)\n",
    "x_train_full, x_test_full, y_train_full, y_test_full = split_test_and_train(\n",
    "    scaled_features, total_labels)\n",
    "trained_svc_3hog = train_linear_svc(x_train_full, x_test_full, y_train_full, y_test_full, 1000.0)\n",
    "print('SVC trained.')\n",
    "\n",
    "# find the cars\n",
    "window_detections_list = find_cars_3hog(test_img, test_windows, WINDOW_SIZE, svm_3hog_scaler, trained_svc_3hog)\n",
    "img_boxed_cars = print_bboxes(test_img, window_detections_list)\n",
    "plt.imshow(img_boxed_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find cars with different size windows\n",
    "def detect_cars_multiSize(img_, window_sizes_, scaler_, classifier_):\n",
    "    imcopy = np.copy(img_)\n",
    "    window_detections_list_total = []\n",
    "    for size in window_sizes_:\n",
    "        #print('detecting in window size {}...'.format(size))\n",
    "        windows = slide_window(imcopy, x_start_stop_=[None, None], y_start_stop_=Y_START_STOP, \n",
    "                    xy_window_=size, xy_overlap_=OVERLAP)\n",
    "        window_detections_list = find_cars_3hog(imcopy, windows, WINDOW_SIZE, scaler_, classifier_)\n",
    "        window_detections_list_total = window_detections_list_total + window_detections_list\n",
    "    imcopy = print_bboxes(img_, window_detections_list_total)    \n",
    "    return imcopy\n",
    "   \n",
    "'''\n",
    "test it...\n",
    "'''\n",
    "WINDOW_SIZES_MULTI = [(64,64),(128,128),(256,256)]\n",
    "img_detect_cars = detect_cars_multiSize(test_img, WINDOW_SIZES_MULTI, svm_3hog_scaler, trained_svc_3hog)\n",
    "plt.imshow(img_detect_cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def detect_on_test_images(img_names_):\n",
    "    is_left = True\n",
    "    for index, name in enumerate(img_names_):\n",
    "        image = imread('test_images/' + name)\n",
    "    \n",
    "        #print('image shape = {}'.format(image.shape))\n",
    "        image = detect_cars_multiSize(image, WINDOW_SIZES_MULTI, svm_3hog_scaler, trained_svc_3hog)\n",
    "    \n",
    "        if is_left:\n",
    "            fig = plt.figure(figsize=(8, 6))\n",
    "            a=fig.add_subplot(1,2,1)\n",
    "            is_left = False\n",
    "        else:    \n",
    "            a=fig.add_subplot(1,2,2)\n",
    "            is_left = True\n",
    "        a.set_title(name)\n",
    "        plt.imshow(image)\n",
    "        \n",
    "'''\n",
    "test it...\n",
    "'''\n",
    "IMG_NAMES = os.listdir('test_images/')\n",
    "detect_on_test_images(IMG_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Negative Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run if not done already..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# $ mkdir non-vehicles/false_positives\n",
    "\n",
    "from matplotlib import interactive\n",
    "interactive(True)\n",
    "\n",
    "def check_false_positive(img_windowed_, name_):\n",
    "    false_positive_num = 0\n",
    "    plt.imshow(img_windowed_)\n",
    "    plt.show()\n",
    "    is_detection = bool(int(input(\"Is this a real detection (0,1): \")))\n",
    "    print (\"you entered...\", is_detection)\n",
    "    if not is_detection:\n",
    "        filename = 'non-vehicles/false_positives/' + name_ + '_' + str(false_positive_num) + '.png'\n",
    "        imsave(filename, img_windowed_)\n",
    "        print('saved as {}'.format(filename))\n",
    "        false_positive_num += 1\n",
    "        \n",
    "def find_cars_3hog_review(img_, window_list_, window_size_, scaler_, classifier_):\n",
    "    rand_color = color_dict[randint(0,5)]\n",
    "    imcopy = np.copy(img_)\n",
    "    img_window = np.zeros(window_size_)\n",
    "    num_detections = 0\n",
    "    window_list_detections = []\n",
    "    # for each window...\n",
    "    bbox_num = 0\n",
    "    for bbox in window_list_:\n",
    "        #print(bbox)\n",
    "        # extract part of img_\n",
    "        top_L_x = bbox[0][0]\n",
    "        top_L_y = bbox[0][1]\n",
    "        bot_R_x = bbox[1][0]\n",
    "        bot_R_y = bbox[1][1]\n",
    "        #print('y = {}:{}'.format(top_L_y, bot_R_y))\n",
    "        #print('x = {}:{}'.format(top_L_x, bot_R_x))\n",
    "        img_window = img_[top_L_y:bot_R_y,top_L_x:bot_R_x,:]\n",
    "        # resize to 64x64\n",
    "        #print(img_window.shape)\n",
    "        img_resized = cv2.resize(img_window, (train_height,train_width))\n",
    "        # extract features\n",
    "        features = extract_features_3hog(img_resized, orient_=ORIENT, \n",
    "                                         pix_per_cell_=PIX_PER_CELL, \n",
    "                                         cell_per_block_=CELL_PER_BLOCK)\n",
    "        features = features.reshape(1, -1)   #stop the executor from complaining\n",
    "        # preprocess features\n",
    "        scaled_features = scaler_.transform(features)\n",
    "        # predict with svc\n",
    "        if classifier_.predict(scaled_features) == 1:\n",
    "            window_list_detections.append(bbox)\n",
    "            num_detections += 1\n",
    "            check_false_positive(img_resized, 'bbox'+str(bbox_num))\n",
    "        bbox_num += 1\n",
    "\n",
    "    print('{} detections.'.format(num_detections))\n",
    "    return window_list_detections \n",
    "\n",
    "def detect_cars_multiSize_review(img_, window_sizes_, scaler_, classifier_):\n",
    "    imcopy = np.copy(img_)\n",
    "    window_detections_list_total = []\n",
    "    for size in window_sizes_:\n",
    "        #print('detecting in window size {}...'.format(size))\n",
    "        windows = slide_window(imcopy, x_start_stop_=[None, None], y_start_stop_=Y_START_STOP, \n",
    "                    xy_window_=size, xy_overlap_=OVERLAP)\n",
    "        window_detections_list = find_cars_3hog_review(imcopy, windows, WINDOW_SIZE, \n",
    "                                                       scaler_, classifier_)\n",
    "        window_detections_list_total = window_detections_list_total + window_detections_list\n",
    "    imcopy = print_bboxes(img_, window_detections_list_total) \n",
    "    return imcopy\n",
    "\n",
    "\n",
    "'''\n",
    "Let's try it...\n",
    "'''\n",
    "is_left = True\n",
    "img_names = os.listdir('test_images/')\n",
    "\n",
    "for index, name in enumerate(img_names):\n",
    "    image = imread('test_images/' + name)\n",
    "    image = detect_cars_multiSize_review(image, WINDOW_SIZES_MULTI, svm_3hog_scaler, trained_svc_3hog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get new list of non-vehicle images\n",
    "\n",
    "notcar_filepaths = []\n",
    "notcar_directories = ['non-vehicles/GTI/',\n",
    "                      'non-vehicles/Extras/',\n",
    "                      'non-vehicles/false_positives/']\n",
    "for folder in notcar_directories:\n",
    "    glob_filenames = glob.glob(folder + '*.png')\n",
    "    add_filenames_to_list(notcar_filepaths, glob_filenames)\n",
    "\n",
    "\n",
    "print('# car_filepaths = {}'.format(len(car_filepaths)))\n",
    "print('# notcar_filepaths = {}'.format(len(notcar_filepaths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# retrain...\n",
    "car_features = extract_features_3hog_files(car_filepaths, orient_=ORIENT,\n",
    "                                           pix_per_cell_=PIX_PER_CELL, \n",
    "                                           cell_per_block_=CELL_PER_BLOCK)\n",
    "notcar_features = extract_features_3hog_files(notcar_filepaths, orient_=ORIENT, \n",
    "                                              pix_per_cell_=PIX_PER_CELL, \n",
    "                                              cell_per_block_=CELL_PER_BLOCK)\n",
    "print('Features found.')\n",
    "\n",
    "# preproces data (redo on color space)\n",
    "scaled_features,svm_3hog_scaler = preprocess_features(car_features, notcar_features)\n",
    "total_labels = create_labels(car_features, notcar_features)\n",
    "print('Data preprocessed.')\n",
    "\n",
    "# split and train (redo on color space)\n",
    "x_train_full, x_test_full, y_train_full, y_test_full = split_test_and_train(\n",
    "    scaled_features, total_labels)\n",
    "trained_svc_3hog = train_linear_svc(x_train_full, x_test_full, y_train_full, y_test_full, \n",
    "                                    1000.0)\n",
    "print('SVC trained.')\n",
    "\n",
    "# find the cars\n",
    "detect_on_test_images(IMG_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Heat Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_heatmap(img_, windows_list_):\n",
    "    img_copy = np.zeros((img_.shape[0],img_.shape[1]), dtype=np.float32)\n",
    "    box_shading = 85  #3 overlaps for 255\n",
    "    for bbox in windows_list_:\n",
    "        # draw box filled in\n",
    "        leftX = bbox[0][0]\n",
    "        topY = bbox[0][1]\n",
    "        rightX = bbox[1][0]\n",
    "        bottomY = bbox[1][1]\n",
    "        img_copy[topY:bottomY, leftX:rightX] += box_shading\n",
    "    # Threshold\n",
    "    img_copy[img_copy[:,:]>255] = 255\n",
    "    return img_copy.astype(np.uint8)\n",
    "\n",
    "'''\n",
    "Test it...\n",
    "'''\n",
    "img_heatmap = print_heatmap(test_img, window_detections_list)\n",
    "plt.imshow(img_heatmap, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blob Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def blob_detection(heatmap_, max_sigma_=200, num_sigma_=10, threshold_=0.005):\n",
    "    img_copy = np.copy(heatmap_)\n",
    "    return blob_doh(img_copy, max_sigma=max_sigma_, num_sigma=num_sigma_, threshold=threshold_)\n",
    "\n",
    "'''\n",
    "Test it...\n",
    "'''\n",
    "blobs_generated = blob_detection(img_heatmap)\n",
    "print(blobs_generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# based on http://scikit-image.org/docs/dev/auto_examples/plot_watershed.html\n",
    "def segmentation(img_):\n",
    "    img_copy = np.copy(img_)\n",
    "    # Generate the markers as local maxima of the distance to the background\n",
    "    distance = ndi.distance_transform_edt(img_copy)\n",
    "    local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((3, 3)),\n",
    "                            labels=img_copy)\n",
    "    markers = ndi.label(local_maxi)[0]\n",
    "    labels = watershed(-distance, markers, mask=img_copy)\n",
    "    return distance, labels\n",
    "\n",
    "'''\n",
    "Test it...\n",
    "'''\n",
    "img_distance, img_segmented = segmentation(img_heatmap)\n",
    "\n",
    "# Display\n",
    "f1, (a11, a12, a13) = plt.subplots(1, 3, figsize=(8, 6))\n",
    "f1.tight_layout()\n",
    "a11.imshow(img_heatmap, cmap='gray')\n",
    "a11.set_title('Heatmap', fontsize=10)\n",
    "a12.imshow(-img_distance, cmap='gray')\n",
    "a12.set_title('Inv Distance', fontsize=10)\n",
    "a13.imshow(img_segmented, cmap='gray')\n",
    "a13.set_title('Image Segmented', fontsize=10)\n",
    "\n",
    "#plt.imshow(img_segmented, cmap='gray')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## blob then watershed\n",
    "def bbox_from_blob_and_seg(blobs_generated_, img_segmented_):\n",
    "    bbox_list = []\n",
    "    for entry in range(blobs_generated_.shape[0]):\n",
    "        blob_row = blobs_generated_[entry][0]\n",
    "        blob_col = blobs_generated_[entry][1]\n",
    "        segment_value = img_segmented_[blob_row, blob_col]\n",
    "        # find left and right bounds\n",
    "        row = img_segmented_[blob_row, :]\n",
    "        row_extent = np.where(row == segment_value)[0]\n",
    "        leftX = row_extent[0]\n",
    "        rightX = row_extent[-1]\n",
    "        # find top and bottom bounds\n",
    "        col = img_segmented_[:, blob_col]\n",
    "        col_extent = np.where(col == segment_value)[0]\n",
    "        topY = col_extent[0]\n",
    "        bottomY = col_extent[-1]\n",
    "        # add new bbox\n",
    "        new_bbox = ((leftX, topY), (rightX, bottomY))\n",
    "        bbox_list.append(new_bbox)\n",
    "        \n",
    "    return bbox_list\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Test it...\n",
    "'''\n",
    "blobs_generated = blob_detection(img_heatmap)\n",
    "_, img_segmented = segmentation(img_heatmap)\n",
    "combined_boxes = bbox_from_blob_and_seg(blobs_generated, img_segmented)\n",
    "img_combined_box = print_bboxes(test_img, combined_boxes)\n",
    "\n",
    "plt.imshow(img_combined_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Calibrated Linear SVC\n",
    "def train_linear_cal_svc(X_train_, X_test_, Y_train_, Y_test_, c_=1.0):\n",
    "    # setup linear support-vector-classifier\n",
    "    svc = LinearSVC(C=c_)\n",
    "    # setup and train calibrated classifier\n",
    "    cal_svc = CalibratedClassifierCV(svc)\n",
    "    cal_svc.fit(X_train_, Y_train_)\n",
    "    # Check the score of the classifier\n",
    "    print('Train Accuracy of SVC = ', cal_svc.score(X_train_, Y_train_))\n",
    "    print('Test Accuracy of SVC = ', cal_svc.score(X_test_, Y_test_))\n",
    "    #y_proba = clf.predict_proba(X_test)\n",
    "    return cal_svc\n",
    "\n",
    "'''\n",
    "test it...\n",
    "'''\n",
    "trained_svc_3hog = train_linear_cal_svc(x_train_full, x_test_full, \n",
    "                                       y_train_full, y_test_full, \n",
    "                                       1000.0)\n",
    "print('SVC trained.')\n",
    "\n",
    "# find the cars\n",
    "detect_on_test_images(IMG_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get detection Probabilities...\n",
    "def find_cars_3hog_prob(img_, window_list_, window_size_, scaler_, classifier_):\n",
    "    img_window = np.zeros(window_size_)\n",
    "    num_detections = 0\n",
    "    window_list_detections = []\n",
    "    # for each window...\n",
    "    for bbox in window_list_:\n",
    "        #print(bbox)\n",
    "        # extract part of img_\n",
    "        top_L_x = bbox[0][0]\n",
    "        top_L_y = bbox[0][1]\n",
    "        bot_R_x = bbox[1][0]\n",
    "        bot_R_y = bbox[1][1]\n",
    "        #print('y = {}:{}'.format(top_L_y, bot_R_y))\n",
    "        #print('x = {}:{}'.format(top_L_x, bot_R_x))\n",
    "        img_window = img_[top_L_y:bot_R_y,top_L_x:bot_R_x,:]\n",
    "        # resize to 64x64\n",
    "        #print(img_window.shape)\n",
    "        img_resized = cv2.resize(img_window, (train_height,train_width))\n",
    "        # extract features\n",
    "        features = extract_features_3hog(img_resized, orient_=ORIENT, \n",
    "                                          pix_per_cell_=PIX_PER_CELL, cell_per_block_=CELL_PER_BLOCK)\n",
    "        features = features.reshape(1, -1)   #stop the executor from complaining\n",
    "        # preprocess features\n",
    "        scaled_features = scaler_.transform(features)\n",
    "        # predict with svc\n",
    "        prediction = classifier_.predict(scaled_features)\n",
    "        prediction_prob_1 = classifier_.predict_proba(scaled_features)[0][1]\n",
    "        if prediction == 1 and prediction_prob_1 > 0.75:\n",
    "            window_list_detections.append(bbox)\n",
    "            num_detections += 1\n",
    "\n",
    "    print('{} detections.'.format(num_detections))\n",
    "    return window_list_detections \n",
    "\n",
    "\n",
    "def detect_cars_multiSize_prob(img_, window_sizes_, scaler_, classifier_):\n",
    "    imcopy = np.copy(img_)\n",
    "    window_detections_list_total = []\n",
    "    for size in window_sizes_:\n",
    "        #print('detecting in window size {}...'.format(size))\n",
    "        windows = slide_window(imcopy, x_start_stop_=[None, None], y_start_stop_=Y_START_STOP, \n",
    "                    xy_window_=size, xy_overlap_=OVERLAP)\n",
    "        window_detections_list = find_cars_3hog_prob(imcopy, windows, WINDOW_SIZE, \n",
    "                                                     scaler_, classifier_)\n",
    "        window_detections_list_total = window_detections_list_total + window_detections_list\n",
    "    imcopy = print_bboxes(img_, window_detections_list_total)    \n",
    "    return imcopy\n",
    "\n",
    "\n",
    "'''\n",
    "test it...\n",
    "'''\n",
    "test_img_cal = imread('test_images/test6.jpg')\n",
    "img_detect_cars = detect_cars_multiSize_prob(test_img_cal, WINDOW_SIZES_MULTI, \n",
    "                                             svm_3hog_scaler, trained_svc_3hog)\n",
    "plt.imshow(img_detect_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
